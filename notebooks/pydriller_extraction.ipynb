{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for commit in pydriller.RepositoryMining(\"..\").traverse_commits():\n",
    "    for m in commit.modifications:\n",
    "        df = df.append([[commit.hash, m.added, m.removed, m.nloc, m.token_count, commit.committer_date, commit.committer_timezone, commit.in_main_branch, m.complexity]])\n",
    "df.rename(columns={0: 'commit_hash', 1: 'linesAdded', 2: 'linesRemoved', 3: 'nloc', 4: 'tokenCount', 5: 'committerDate', 6: 'committerTimezone', 7: 'inMainBranch', 8: 'complexity'}, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df['nloc'] = df.nloc.astype('int')\n",
    "df['complexity'] = df.complexity.astype('int')\n",
    "df['tokenCount'] = df.tokenCount.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp1 = df.groupby('commit_hash', as_index=False).sum()[['commit_hash', 'nloc', 'linesAdded', 'linesRemoved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp2 = df.groupby('commit_hash', as_index=False).mean()[['commit_hash', 'tokenCount', 'complexity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp3 = df.groupby('commit_hash', as_index=False).max()[['commit_hash', 'tokenCount', 'complexity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp4 = df.groupby('commit_hash', as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp4['changedFiles'] = grp4['linesAdded']\n",
    "grp4 = grp4[['commit_hash', 'changedFiles']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.merge(grp1, how='left', on='commit_hash', suffixes=['', 'total']) \\\n",
    "             .merge(grp2, how='left', on='commit_hash', suffixes=['', 'mean']) \\\n",
    "             .merge(grp3, how='left', on='commit_hash', suffixes=['', 'max']) \\\n",
    "             .merge(grp4, how='left', on='commit_hash', suffixes=['', 'Files']) \\\n",
    "             .drop(columns=['linesAdded', 'linesRemoved', 'nloc', 'tokenCount', 'complexity']) \\\n",
    "             .rename(columns={'linesAddedtotal': 'totalLinesAdded', 'linesRemovedtotal': 'totalLinesRemoved',\n",
    "                              'complexitymax': 'maxComplexity', 'complexitymean': 'meanComplexity',\n",
    "                              'tokenCountmean': 'meanTokenCount', 'tokenCountmax': 'maxTokenCount',\n",
    "                              'nloctotal': 'totalNloc'}) \\\n",
    "             .reset_index(drop=True) \\\n",
    "             .drop_duplicates(subset=['commit_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['committerDate'] = pd.to_datetime(final_df.committerDate, utc=True)\n",
    "final_df['committerTimezone'] = final_df.committerTimezone.astype('int')\n",
    "final_df['committerDateLocal'] = final_df.apply(lambda x: x.committerDate + np.timedelta64(x.committerTimezone,'s'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_days = final_df.committerDateLocal.dt.dayofweek\n",
    "final_df = pd.concat([final_df, pd.get_dummies(week_days, prefix='dayOfWeek')], axis=1)\n",
    "final_df['committerHourOfDay'] = final_df.committerDateLocal.apply(lambda x: x.hour)\n",
    "final_df.drop(columns=['committerDate', 'committerDateLocal', 'committerTimezone'], inplace=True)\n",
    "final_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    if 'dayOfWeek_{}'.format(i) not in final_df.columns:\n",
    "        final_df['dayOfWeek_{}'.format(i)] = 0\n",
    "final_df = final_df[['commit_hash', 'inMainBranch', 'maxComplexity', 'meanComplexity', 'totalLinesAdded',\n",
    "       'totalLinesRemoved', 'totalNloc', 'maxTokenCount', 'meanTokenCount',\n",
    "       'changedFiles', 'dayOfWeek_0', 'dayOfWeek_1', 'dayOfWeek_2',\n",
    "       'dayOfWeek_3', 'dayOfWeek_4', 'dayOfWeek_5', 'dayOfWeek_6',\n",
    "       'committerHourOfDay']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "        \n",
    "def df_to_json(df, json_filename='test.json'):\n",
    "    lst = []\n",
    "    for i in range(df.shape[0]):\n",
    "        lst.append(dict())\n",
    "        for j, col in enumerate(df.columns.tolist()):\n",
    "            lst[i][col] = df.iloc[i,j] if col != 'inMainBranch' else int(df.iloc[i, j])\n",
    "    with open(json_filename, 'w') as fb:\n",
    "        json.dump(lst, fb, cls=NpEncoder)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'commit_hash': 'f61598c75f9d23664fb95badb750cd81b55b4d7a',\n",
       "  'inMainBranch': 1,\n",
       "  'maxComplexity': 4,\n",
       "  'meanComplexity': 1.25,\n",
       "  'totalLinesAdded': 309,\n",
       "  'totalLinesRemoved': 0,\n",
       "  'totalNloc': 75,\n",
       "  'maxTokenCount': 122,\n",
       "  'meanTokenCount': 86.5,\n",
       "  'changedFiles': 4,\n",
       "  'dayOfWeek_0': 0,\n",
       "  'dayOfWeek_1': 1,\n",
       "  'dayOfWeek_2': 0,\n",
       "  'dayOfWeek_3': 0,\n",
       "  'dayOfWeek_4': 0,\n",
       "  'dayOfWeek_5': 0,\n",
       "  'dayOfWeek_6': 0,\n",
       "  'committerHourOfDay': 10},\n",
       " {'commit_hash': 'c18192f3c488ac26bffec719f89523f82244420c',\n",
       "  'inMainBranch': 1,\n",
       "  'maxComplexity': 4,\n",
       "  'meanComplexity': 3.0,\n",
       "  'totalLinesAdded': 62,\n",
       "  'totalLinesRemoved': 2,\n",
       "  'totalNloc': 69,\n",
       "  'maxTokenCount': 326,\n",
       "  'meanTokenCount': 320.0,\n",
       "  'changedFiles': 2,\n",
       "  'dayOfWeek_0': 0,\n",
       "  'dayOfWeek_1': 0,\n",
       "  'dayOfWeek_2': 0,\n",
       "  'dayOfWeek_3': 0,\n",
       "  'dayOfWeek_4': 0,\n",
       "  'dayOfWeek_5': 0,\n",
       "  'dayOfWeek_6': 1,\n",
       "  'committerHourOfDay': 14},\n",
       " {'commit_hash': 'e8a48664da1a6af462d4b312df6d0c95ae4632d9',\n",
       "  'inMainBranch': 1,\n",
       "  'maxComplexity': 11,\n",
       "  'meanComplexity': 7.5,\n",
       "  'totalLinesAdded': 61,\n",
       "  'totalLinesRemoved': 1,\n",
       "  'totalNloc': 80,\n",
       "  'maxTokenCount': 324,\n",
       "  'meanTokenCount': 319.0,\n",
       "  'changedFiles': 2,\n",
       "  'dayOfWeek_0': 0,\n",
       "  'dayOfWeek_1': 0,\n",
       "  'dayOfWeek_2': 0,\n",
       "  'dayOfWeek_3': 0,\n",
       "  'dayOfWeek_4': 0,\n",
       "  'dayOfWeek_5': 1,\n",
       "  'dayOfWeek_6': 0,\n",
       "  'committerHourOfDay': 17}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_json(final_df, '../data/processed/inference_test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
